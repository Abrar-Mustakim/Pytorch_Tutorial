{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn  \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep\n",
      "-------------------------------------\n",
      "Lizard\n"
     ]
    }
   ],
   "source": [
    "class Lizard:\n",
    "    def __init__(self, name):\n",
    "        self.name = name   \n",
    "\n",
    "    def set_name(self, name):\n",
    "        self.name = name  \n",
    "\n",
    "lizard = Lizard(\"Deep\") \n",
    "print(lizard.name)\n",
    "print(\"-------------------------------------\") \n",
    "lizard.set_name(\"Lizard\")\n",
    "print(lizard.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Build a Neural Network in Pytorch </h3>\n",
    "<p> Extend the nn.Module based class </p><br>\n",
    "<p> Define Layer as Class Attribute </p> <br>\n",
    "<p> Implement the forward() methods </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) \n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5) \n",
    "        self.fc1 = nn.Linear(12*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 60)\n",
    "        self.out = nn.Linear(60, 10)\n",
    "\n",
    "\n",
    "    def forward(self, L):\n",
    "        return L "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = Network()\n",
    "network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.0939,  0.0048, -0.1999,  0.0968,  0.0077],\n",
       "          [-0.0649, -0.1726, -0.1477,  0.0036, -0.1025],\n",
       "          [ 0.0193,  0.0098, -0.0959,  0.1758,  0.0541],\n",
       "          [ 0.0255, -0.1558, -0.0982,  0.1168,  0.1888],\n",
       "          [-0.1657, -0.0571, -0.0172,  0.1798, -0.1622]]],\n",
       "\n",
       "\n",
       "        [[[-0.1264, -0.1943, -0.0878,  0.0592, -0.0752],\n",
       "          [-0.0039, -0.1530,  0.1580, -0.0319,  0.1512],\n",
       "          [-0.1146, -0.0404, -0.1269, -0.1491, -0.0676],\n",
       "          [-0.1278, -0.1200, -0.1024, -0.1345, -0.0508],\n",
       "          [-0.0299,  0.0596, -0.1516, -0.1063, -0.0867]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1756, -0.0289,  0.1422,  0.1002,  0.0533],\n",
       "          [-0.0532,  0.1029, -0.0226, -0.1996, -0.1043],\n",
       "          [-0.0711,  0.0916,  0.0417,  0.0202, -0.1231],\n",
       "          [-0.0339, -0.0727,  0.1914,  0.0345,  0.0618],\n",
       "          [-0.1503,  0.0382, -0.0398,  0.1288,  0.0458]]],\n",
       "\n",
       "\n",
       "        [[[-0.0550,  0.1844,  0.0311, -0.1939,  0.0004],\n",
       "          [-0.1149, -0.1934, -0.1549,  0.1055,  0.0998],\n",
       "          [ 0.1363,  0.1067,  0.0158, -0.1383,  0.1917],\n",
       "          [ 0.1690,  0.1746, -0.0593, -0.0715,  0.1267],\n",
       "          [-0.0222, -0.0608,  0.1181, -0.0964,  0.0554]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1450,  0.1471,  0.1298,  0.0355,  0.1548],\n",
       "          [-0.1000,  0.1097, -0.0121, -0.0388,  0.1276],\n",
       "          [-0.1010, -0.0104,  0.1617,  0.1790, -0.0224],\n",
       "          [ 0.0531, -0.0266,  0.0615,  0.0786,  0.1022],\n",
       "          [-0.1198, -0.1061,  0.1916, -0.0627,  0.1217]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0041, -0.1943,  0.0659, -0.1184,  0.1995],\n",
       "          [ 0.1267,  0.1828,  0.0719,  0.1237,  0.0407],\n",
       "          [-0.0177, -0.0315, -0.0539,  0.1728, -0.0106],\n",
       "          [ 0.1781, -0.0115, -0.1226, -0.0787,  0.1601],\n",
       "          [-0.1078,  0.1844, -0.0522,  0.1282,  0.0087]]]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1401,  0.0535,  0.0093, -0.0567, -0.0476, -0.1650],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 5, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv1.weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000001FFC99B5740>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([12, 6, 5, 5])\n",
      "torch.Size([12])\n",
      "torch.Size([120, 192])\n",
      "torch.Size([120])\n",
      "torch.Size([60, 120])\n",
      "torch.Size([60])\n",
      "torch.Size([10, 60])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in network.parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t\t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias \t\t torch.Size([6])\n",
      "conv2.weight \t\t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t\t torch.Size([12])\n",
      "fc1.weight \t\t torch.Size([120, 192])\n",
      "fc1.bias \t\t torch.Size([120])\n",
      "fc2.weight \t\t torch.Size([60, 120])\n",
      "fc2.bias \t\t torch.Size([60])\n",
      "out.weight \t\t torch.Size([10, 60])\n",
      "out.bias \t\t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in network.named_parameters():\n",
    "    print(name,  '\\t\\t', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = torch.Tensor([1, 2, 3, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_features.type(torch.float64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_features.type(torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = torch.Tensor([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix.dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 30.,  70., 110.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix.matmul(in_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Convolutional Neural Network </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3) \n",
    "        self.relu = nn.ReLU() \n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128*28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, classes)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.conv1(X)\n",
    "        x = self.relu(x) \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x) \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x) \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu): ReLU()\n",
      "  (linear): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=100352, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN(10) \n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (linear): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=100352, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3), \n",
    "        nn.ReLU() \n",
    "        )\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128*28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, classes)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.conv(X)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x) \n",
    "        return x \n",
    "    \n",
    "\n",
    "cnn = CNN(10) \n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.0.weight \t\t torch.Size([32, 1, 3, 3])\n",
      "conv.0.bias \t\t torch.Size([32])\n",
      "conv.1.weight \t\t torch.Size([64, 32, 3, 3])\n",
      "conv.1.bias \t\t torch.Size([64])\n",
      "conv.2.weight \t\t torch.Size([128, 64, 3, 3])\n",
      "conv.2.bias \t\t torch.Size([128])\n",
      "linear.1.weight \t\t torch.Size([512, 100352])\n",
      "linear.1.bias \t\t torch.Size([512])\n",
      "linear.4.weight \t\t torch.Size([10, 512])\n",
      "linear.4.bias \t\t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in cnn.named_parameters():\n",
    "    print(name,  '\\t\\t', param.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
